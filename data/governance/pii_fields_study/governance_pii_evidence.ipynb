{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556a306f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_ROOT = C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\n",
      "GOV_DIR (outputs will be saved here) = C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\governance\\pii_fields_study\n",
      "Using pii_inventory.csv = C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\quality\\pii_inventory.csv\n",
      "pii_inventory columns: ['field_path', 'classification', 'present_in_raw', 'present_in_curated', 'present_in_analysis']\n",
      "Exported: C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\governance\\pii_fields_study\\pii_presence_matrix.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>field_name</th>\n",
       "      <th>pii_class</th>\n",
       "      <th>present_in_raw</th>\n",
       "      <th>present_in_curated</th>\n",
       "      <th>present_in_analysis</th>\n",
       "      <th>notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age_band</td>\n",
       "      <td>Non-PII</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>applicant_info.date_of_birth</td>\n",
       "      <td>PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>applicant_info.email</td>\n",
       "      <td>PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>applicant_info.full_name</td>\n",
       "      <td>PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>applicant_info.ip_address</td>\n",
       "      <td>PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>applicant_info.ssn</td>\n",
       "      <td>PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>applicant_info.gender</td>\n",
       "      <td>Quasi-PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>applicant_info.zip_code</td>\n",
       "      <td>Quasi-PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>applicant_pseudo_id</td>\n",
       "      <td>Quasi-PII</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>application_id</td>\n",
       "      <td>Quasi-PII</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     field_name  pii_class  present_in_raw  \\\n",
       "0                      age_band    Non-PII           False   \n",
       "1  applicant_info.date_of_birth        PII            True   \n",
       "2          applicant_info.email        PII            True   \n",
       "3      applicant_info.full_name        PII            True   \n",
       "5     applicant_info.ip_address        PII            True   \n",
       "6            applicant_info.ssn        PII            True   \n",
       "4         applicant_info.gender  Quasi-PII            True   \n",
       "7       applicant_info.zip_code  Quasi-PII            True   \n",
       "8           applicant_pseudo_id  Quasi-PII           False   \n",
       "9                application_id  Quasi-PII            True   \n",
       "\n",
       "   present_in_curated  present_in_analysis notes  \n",
       "0               False                 True        \n",
       "1                True                False        \n",
       "2                True                False        \n",
       "3                True                False        \n",
       "5                True                False        \n",
       "6                True                False        \n",
       "4                True                 True        \n",
       "7                True                 True        \n",
       "8               False                 True        \n",
       "9                True                 True        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Direct PII list saved to: C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\governance\\pii_fields_study\\direct_pii_fields_list.txt\n",
      "Sample direct PII fields: ['applicant_info.date_of_birth', 'applicant_info.email', 'applicant_info.full_name', 'applicant_info.ip_address', 'applicant_info.ssn']\n",
      "Loaded analysis dataset: C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\curated\\applications_analysis.csv\n",
      "Rows, Cols: (500, 16)\n",
      "Direct PII columns found (exact match): []\n",
      "Direct PII columns found (leaf-name match): []\n",
      "Saved: C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\governance\\pii_fields_study\\analysis_pii_leakage_scan_summary.csv\n",
      "Saved: C:\\Users\\anton\\OneDrive - Nova SBE\\Nova\\S2\\DEGO\\DEGO_GP\\DEGO_Project_Group03\\data\\governance\\pii_fields_study\\analysis_pii_leakage_by_column.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pattern</th>\n",
       "      <th>sample_size_rows</th>\n",
       "      <th>columns_scanned</th>\n",
       "      <th>cell_hits</th>\n",
       "      <th>columns_with_hits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>email_like</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ip_like</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ssn_like</td>\n",
       "      <td>300</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      pattern  sample_size_rows  columns_scanned  cell_hits  columns_with_hits\n",
       "0  email_like               300                6          0                  0\n",
       "1     ip_like               300                6          0                  0\n",
       "2    ssn_like               300                6          0                  0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    from IPython.display import display\n",
    "except Exception:\n",
    "    display = print\n",
    "\n",
    "\n",
    "\n",
    "# Repo root discovery + helpers\n",
    "def _is_repo_root(p: Path) -> bool:\n",
    "    \"\"\"Repo root should contain 'data' and at least one code marker.\"\"\"\n",
    "    if not (p / \"data\").is_dir():\n",
    "        return False\n",
    "    code_markers = [p / \"src\", p / \".git\", p / \"pyproject.toml\", p / \"requirements.txt\", p / \"README.md\"]\n",
    "    return any(m.exists() for m in code_markers)\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    start = start.resolve()\n",
    "    for p in [start] + list(start.parents):\n",
    "        if _is_repo_root(p):\n",
    "            return p\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / \"data\" / \"curated\").is_dir() or (p / \"data\" / \"quality\").is_dir():\n",
    "            return p\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not locate REPO_ROOT. Expected a folder containing 'data' and (src/.git/pyproject.toml/requirements.txt/README.md).\"\n",
    "    )\n",
    "\n",
    "def first_existing(paths: list[Path]) -> Path | None:\n",
    "    for p in paths:\n",
    "        if p is not None and p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "def find_file_in_data(repo_root: Path, filename: str) -> Path | None:\n",
    "    \"\"\"Search inside repo_root/data for the first occurrence of filename.\"\"\"\n",
    "    data_dir = repo_root / \"data\"\n",
    "    if not data_dir.is_dir():\n",
    "        return None\n",
    "    try:\n",
    "        for p in data_dir.rglob(filename):\n",
    "            if p.is_file():\n",
    "                return p\n",
    "    except Exception:\n",
    "        return None\n",
    "    return None\n",
    "\n",
    "def find_all(repo_root: Path, filename: str) -> list[Path]:\n",
    "    \"\"\"Find all occurrences of a file under the repo.\"\"\"\n",
    "    return [p for p in repo_root.rglob(filename) if p.is_file()]\n",
    "\n",
    "\n",
    "# Locate repo + stable output folder\n",
    "REPO_ROOT = find_repo_root(Path.cwd())\n",
    "repo_root_str = str(REPO_ROOT)\n",
    "if repo_root_str not in sys.path:\n",
    "    sys.path.insert(0, repo_root_str)\n",
    "\n",
    "print(\"REPO_ROOT =\", REPO_ROOT)\n",
    "\n",
    "# Always write outputs to this canonical folder\n",
    "GOV_DIR = REPO_ROOT / \"data\" / \"governance\" / \"pii_fields_study\"\n",
    "GOV_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"GOV_DIR (outputs will be saved here) =\", GOV_DIR)\n",
    "\n",
    "\n",
    "# Load the correct pii_inventory.csv (handle multiple versions)\n",
    "def pick_best_pii_inventory(paths: list[Path]) -> tuple[Path, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Prefer the canonical inventory with:\n",
    "      field_path, classification, present_in, notes/purpose\n",
    "    Fallback to a pre-processed version with:\n",
    "      field_path, classification, present_in_raw/curated/analysis\n",
    "    \"\"\"\n",
    "    scored = []\n",
    "    for p in paths:\n",
    "        try:\n",
    "            df = pd.read_csv(p)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        cols = set(df.columns)\n",
    "\n",
    "        canonical = {\"field_path\", \"classification\", \"present_in\"}\n",
    "        canonical_score = 3 if canonical.issubset(cols) else 0\n",
    "        notes_score = 1 if (\"notes/purpose\" in cols) else 0\n",
    "\n",
    "        processed = {\"field_path\", \"classification\", \"present_in_raw\", \"present_in_curated\", \"present_in_analysis\"}\n",
    "        processed_score = 2 if processed.issubset(cols) else 0\n",
    "\n",
    "        score = canonical_score + notes_score + processed_score\n",
    "        scored.append((score, p, df))\n",
    "\n",
    "    if not scored:\n",
    "        raise FileNotFoundError(\"Could not read any pii_inventory.csv found in the repository.\")\n",
    "\n",
    "    scored.sort(key=lambda x: (x[0], -len(x[2].columns)), reverse=True)\n",
    "    best_score, best_path, best_df = scored[0]\n",
    "\n",
    "    if best_score == 0:\n",
    "        raise ValueError(\n",
    "            \"Found pii_inventory.csv files but none match expected schemas.\\n\"\n",
    "            \"Candidates:\\n\" + \"\\n\".join([str(s[1]) for s in scored[:10]])\n",
    "        )\n",
    "\n",
    "    # Inform if multiple matches exist\n",
    "    if len(scored) > 1:\n",
    "        top_paths = [str(s[1]) for s in scored[:5]]\n",
    "        print(\"PII inventory candidates (top 5 by schema score):\")\n",
    "        for t in top_paths:\n",
    "            print(\" -\", t)\n",
    "\n",
    "    return best_path, best_df\n",
    "\n",
    "all_pii_paths = find_all(REPO_ROOT, \"pii_inventory.csv\")\n",
    "if not all_pii_paths:\n",
    "    raise FileNotFoundError(\"No pii_inventory.csv found anywhere under the repo.\")\n",
    "\n",
    "PII_PATH, pii = pick_best_pii_inventory(all_pii_paths)\n",
    "\n",
    "print(\"Using pii_inventory.csv =\", PII_PATH)\n",
    "print(\"pii_inventory columns:\", pii.columns.tolist())\n",
    "\n",
    "# Normalize into a standard internal schema:\n",
    "# ensure we always have: field_path, classification, notes/purpose, present_in_raw, present_in_curated, present_in_analysis\n",
    "if \"present_in\" in pii.columns:\n",
    "    if \"notes/purpose\" not in pii.columns:\n",
    "        pii[\"notes/purpose\"] = \"\"\n",
    "\n",
    "    def parse_presence(x: str) -> set[str]:\n",
    "        if pd.isna(x):\n",
    "            return set()\n",
    "        s = str(x).strip().lower()\n",
    "        for sep in [\"|\", \",\", \";\", \" \"]:\n",
    "            s = s.replace(sep, \"|\")\n",
    "        parts = [p for p in s.split(\"|\") if p]\n",
    "        return set(parts)\n",
    "\n",
    "    presence_sets = pii[\"present_in\"].apply(parse_presence)\n",
    "    pii[\"present_in_raw\"] = presence_sets.apply(lambda s: \"raw\" in s)\n",
    "    pii[\"present_in_curated\"] = presence_sets.apply(lambda s: \"curated\" in s)\n",
    "    pii[\"present_in_analysis\"] = presence_sets.apply(lambda s: \"analysis\" in s)\n",
    "\n",
    "else:\n",
    "    needed = {\"present_in_raw\", \"present_in_curated\", \"present_in_analysis\"}\n",
    "    if not needed.issubset(set(pii.columns)):\n",
    "        raise ValueError(\n",
    "            \"pii_inventory.csv does not contain 'present_in' nor the processed 'present_in_*' columns.\\n\"\n",
    "            f\"Columns found: {pii.columns.tolist()}\"\n",
    "        )\n",
    "    if \"notes/purpose\" not in pii.columns:\n",
    "        pii[\"notes/purpose\"] = \"\"\n",
    "\n",
    "# Confirm minimum columns now\n",
    "required = {\"field_path\", \"classification\", \"notes/purpose\", \"present_in_raw\", \"present_in_curated\", \"present_in_analysis\"}\n",
    "missing = required - set(pii.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"After normalization, missing required columns: {missing}. Columns: {pii.columns.tolist()}\")\n",
    "\n",
    "\n",
    "# Normalize classification to pii_class\n",
    "def norm_class(x: str) -> str:\n",
    "    if pd.isna(x):\n",
    "        return \"Unknown\"\n",
    "    s = str(x).strip()\n",
    "    s_lower = s.lower()\n",
    "    if s_lower == \"pii\":\n",
    "        return \"PII\"\n",
    "    if \"quasi\" in s_lower:\n",
    "        return \"Quasi-PII\"\n",
    "    if \"non\" in s_lower:\n",
    "        return \"Non-PII\"\n",
    "    return s\n",
    "\n",
    "pii[\"pii_class\"] = pii[\"classification\"].apply(norm_class)\n",
    "\n",
    "\n",
    "# Create PII presence matrix + export\n",
    "matrix = (\n",
    "    pii[\n",
    "        [\n",
    "            \"field_path\",\n",
    "            \"pii_class\",\n",
    "            \"present_in_raw\",\n",
    "            \"present_in_curated\",\n",
    "            \"present_in_analysis\",\n",
    "            \"notes/purpose\",\n",
    "        ]\n",
    "    ]\n",
    "    .rename(columns={\"field_path\": \"field_name\", \"notes/purpose\": \"notes\"})\n",
    "    .sort_values([\"pii_class\", \"field_name\"], ascending=[True, True])\n",
    ")\n",
    "\n",
    "OUT_MATRIX = GOV_DIR / \"pii_presence_matrix.csv\"\n",
    "matrix.to_csv(OUT_MATRIX, index=False)\n",
    "print(\"Exported:\", OUT_MATRIX)\n",
    "display(matrix.head(10))\n",
    "\n",
    "\n",
    "# Direct PII list + export\n",
    "direct_pii_fields = (\n",
    "    pii.loc[pii[\"pii_class\"] == \"PII\", \"field_path\"]\n",
    "    .dropna()\n",
    "    .astype(str)\n",
    "    .sort_values()\n",
    "    .unique()\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "OUT_DIRECT = GOV_DIR / \"direct_pii_fields_list.txt\"\n",
    "OUT_DIRECT.write_text(\"\\n\".join(direct_pii_fields), encoding=\"utf-8\")\n",
    "print(\"Direct PII list saved to:\", OUT_DIRECT)\n",
    "print(\"Sample direct PII fields:\", direct_pii_fields[:10])\n",
    "\n",
    "\n",
    "# Load applications_analysis.csv \n",
    "analysis_candidates = [\n",
    "    REPO_ROOT / \"data\" / \"curated\" / \"applications_analysis.csv\",\n",
    "    REPO_ROOT / \"data\" / \"curated\" / \"applications_analysis_clean.csv\",\n",
    "]\n",
    "\n",
    "analysis_path = first_existing(analysis_candidates) or find_file_in_data(REPO_ROOT, \"applications_analysis.csv\")\n",
    "if analysis_path is None:\n",
    "    searched = \"\\n\".join([f\" - {p}\" for p in analysis_candidates] + [\" - (searched under data/**/applications_analysis.csv)\"])\n",
    "    raise FileNotFoundError(\"Could not find applications_analysis.csv.\\nSearched:\\n\" + searched)\n",
    "\n",
    "analysis = pd.read_csv(analysis_path)\n",
    "print(\"Loaded analysis dataset:\", analysis_path)\n",
    "print(\"Rows, Cols:\", analysis.shape)\n",
    "\n",
    "\n",
    "# Direct PII column checks \n",
    "direct_set = set(direct_pii_fields)\n",
    "exact_present = [c for c in analysis.columns if c in direct_set]\n",
    "\n",
    "direct_leaf = {f.split(\".\")[-1].lower() for f in direct_pii_fields}\n",
    "leaf_present = [c for c in analysis.columns if c.lower() in direct_leaf]\n",
    "\n",
    "print(\"Direct PII columns found (exact match):\", exact_present)\n",
    "print(\"Direct PII columns found (leaf-name match):\", leaf_present)\n",
    "\n",
    "\n",
    "\n",
    "# 9) Leakage scan (object columns only, count-only outputs)\n",
    "scan_df = analysis.select_dtypes(include=[\"object\"]).fillna(\"\").astype(str)\n",
    "\n",
    "if scan_df.shape[1] == 0:\n",
    "    print(\"No object columns to scan for leakage patterns.\")\n",
    "    leak_summary = pd.DataFrame(columns=[\"pattern\", \"sample_size_rows\", \"columns_scanned\", \"cell_hits\", \"columns_with_hits\"])\n",
    "    display(leak_summary)\n",
    "else:\n",
    "    sample = scan_df.sample(min(len(scan_df), 300), random_state=42)\n",
    "\n",
    "    patterns = {\n",
    "        \"email_like\": re.compile(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b\"),\n",
    "        \"ip_like\": re.compile(r\"\\b(?:\\d{1,3}\\.){3}\\d{1,3}\\b\"),\n",
    "        \"ssn_like\": re.compile(r\"\\b\\d{3}-\\d{2}-\\d{4}\\b\"),\n",
    "    }\n",
    "\n",
    "    # Summary table\n",
    "    results = []\n",
    "    for name, pat in patterns.items():\n",
    "        per_col_hits = sample.apply(lambda col: col.str.contains(pat, regex=True, na=False).sum())\n",
    "        cell_hits = int(per_col_hits.sum())\n",
    "        col_hits = int((per_col_hits > 0).sum())\n",
    "        results.append({\n",
    "            \"pattern\": name,\n",
    "            \"sample_size_rows\": len(sample),\n",
    "            \"columns_scanned\": sample.shape[1],\n",
    "            \"cell_hits\": cell_hits,\n",
    "            \"columns_with_hits\": col_hits,\n",
    "        })\n",
    "\n",
    "    leak_summary = pd.DataFrame(results)\n",
    "\n",
    "    OUT_SUMMARY = GOV_DIR / \"analysis_pii_leakage_scan_summary.csv\"\n",
    "    leak_summary.to_csv(OUT_SUMMARY, index=False)\n",
    "    print(\"Saved:\", OUT_SUMMARY)\n",
    "\n",
    "    # Column-level details (only column names + counts, no values)\n",
    "    hit_details = []\n",
    "    for name, pat in patterns.items():\n",
    "        per_col_hits = sample.apply(lambda col: col.str.contains(pat, regex=True, na=False).sum())\n",
    "        cols_with_hits = per_col_hits[per_col_hits > 0].sort_values(ascending=False)\n",
    "        for col_name, n in cols_with_hits.items():\n",
    "            hit_details.append({\"pattern\": name, \"column\": col_name, \"hits\": int(n)})\n",
    "\n",
    "    hit_details_df = pd.DataFrame(hit_details)\n",
    "\n",
    "    OUT_COLS = GOV_DIR / \"analysis_pii_leakage_by_column.csv\"\n",
    "    hit_details_df.to_csv(OUT_COLS, index=False)\n",
    "    print(\"Saved:\", OUT_COLS)\n",
    "\n",
    "    display(leak_summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
